{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "\n",
    "dotenv_path = Path('/Users/sanchaynibagade/Documents/github/grant_matching/env/mistral.env')\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "MY_KEY = os.getenv('MISTRAL_KEY')\n",
    "os.environ[\"MISTRAL_API_KEY\"] = MY_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "professionalism_example_score_2 = mlflow.metrics.genai.EvaluationExample(\n",
    "    input=\"What is MLflow?\",\n",
    "    output=(\n",
    "        \"MLflow is like your friendly neighborhood toolkit for managing your machine learning projects. It helps \"\n",
    "        \"you track experiments, package your code and models, and collaborate with your team, making the whole ML \"\n",
    "        \"workflow smoother. It's like your Swiss Army knife for machine learning!\"\n",
    "    ),\n",
    "    score=2,\n",
    "    justification=(\n",
    "        \"The response is written in a casual tone. It uses contractions, filler words such as 'like', and \"\n",
    "        \"exclamation points, which make it sound less professional. \"\n",
    "    ),\n",
    ")\n",
    "professionalism_example_score_4 = mlflow.metrics.genai.EvaluationExample(\n",
    "    input=\"What is MLflow?\",\n",
    "    output=(\n",
    "        \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) lifecycle. It was \"\n",
    "        \"developed by Databricks, a company that specializes in big data and machine learning solutions. MLflow is \"\n",
    "        \"designed to address the challenges that data scientists and machine learning engineers face when \"\n",
    "        \"developing, training, and deploying machine learning models.\",\n",
    "    ),\n",
    "    score=4,\n",
    "    justification=(\"The response is written in a formal language and a neutral tone. \"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "professionalism = mlflow.metrics.genai.make_genai_metric(\n",
    "    name=\"professionalism\",\n",
    "    definition=(\n",
    "        \"Professionalism refers to the use of a formal, respectful, and appropriate style of communication that is \"\n",
    "        \"tailored to the context and audience. It often involves avoiding overly casual language, slang, or \"\n",
    "        \"colloquialisms, and instead using clear, concise, and respectful language.\"\n",
    "    ),\n",
    "    grading_prompt=(\n",
    "        \"Professionalism: If the answer is written using a professional tone, below are the details for different scores: \"\n",
    "        \"- Score 0: Language is extremely casual, informal, and may include slang or colloquialisms. Not suitable for \"\n",
    "        \"professional contexts.\"\n",
    "        \"- Score 1: Language is casual but generally respectful and avoids strong informality or slang. Acceptable in \"\n",
    "        \"some informal professional settings.\"\n",
    "        \"- Score 2: Language is overall formal but still have casual words/phrases. Borderline for professional contexts.\"\n",
    "        \"- Score 3: Language is balanced and avoids extreme informality or formality. Suitable for most professional contexts. \"\n",
    "        \"- Score 4: Language is noticeably formal, respectful, and avoids casual elements. Appropriate for formal \"\n",
    "        \"business or academic settings. \"\n",
    "    ),\n",
    "    examples=[professionalism_example_score_2, professionalism_example_score_4],\n",
    "    model=\"mistral:/mistral-small-latest\",\n",
    "    parameters={\"temperature\": 0.0},\n",
    "    aggregations=[\"mean\", \"variance\"],\n",
    "    greater_is_better=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "res = professionalism(  inputs=\"What is MLflow?\",\n",
    "                  predictions=\"MLflow is an open-source platform for managing the end-to-end ML lifecycle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4],\n",
       " ['The response is concise, clear, and uses formal language. It avoids any casual elements, slang, or colloquialisms, making it suitable for formal business or academic settings.'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.scores, res.justifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1],\n",
       " ['The response uses overly casual language and colloquialisms such as \"chill buddy,\" \"saves your butt,\" and \"things get messy,\" which are not suitable for professional contexts.'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = \"\"\"MLflow’s like a chill buddy that remembers all your ML experiments so you don’t have to.\n",
    "It logs your stuff, tracks results, and keeps your models in one place.\n",
    "Basically, it saves your butt when things get messy.\"\"\"\n",
    "\n",
    "res = professionalism(  inputs=\"What is MLflow?\",\n",
    "                        predictions=predictions\n",
    "                        )\n",
    "res.scores, res.justifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
